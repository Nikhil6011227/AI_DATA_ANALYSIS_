{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1**: Checking Null Values for Completeness\n",
    "\n",
    "**Description**: Verify if there are any null values in a dataset, which indicate incomplete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Values in Dataset:\n",
      "    Name    Age  Email\n",
      "0  False  False  False\n",
      "1  False   True  False\n",
      "2   True  False  False\n",
      "3  False  False   True\n",
      "\n",
      "Count of Null Values per Column:\n",
      "Name     1\n",
      "Age      1\n",
      "Email    1\n",
      "dtype: int64\n",
      "\n",
      "Dataset contains missing values.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample dataset with some missing values\n",
    "data = {\n",
    "    \"Name\": [\"Alice\", \"Bob\", None, \"David\"],\n",
    "    \"Age\": [25, None, 30, 22],\n",
    "    \"Email\": [\"alice@example.com\", \"bob@example.com\", \"charlie@example.com\", None]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check for null values (True if null)\n",
    "null_mask = df.isnull()\n",
    "\n",
    "print(\"Null Values in Dataset:\")\n",
    "print(null_mask)\n",
    "\n",
    "# Count total nulls per column\n",
    "null_counts = df.isnull().sum()\n",
    "\n",
    "print(\"\\nCount of Null Values per Column:\")\n",
    "print(null_counts)\n",
    "\n",
    "# Check if dataset has any null values\n",
    "if df.isnull().values.any():\n",
    "    print(\"\\nDataset contains missing values.\")\n",
    "else:\n",
    "    print(\"\\nDataset is complete with no missing values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2**: Checking Data Type Validity\n",
    "\n",
    "**Description**: Ensure that columns contain data of expected types, e.g., ages are integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type Validity per Cell (True=valid, False=invalid):\n",
      "   Name    Age  Email\n",
      "0  True   True   True\n",
      "1  True  False   True\n",
      "2  True   True   True\n",
      "3  True   True   True\n",
      "\n",
      "Rows with Invalid Data Types:\n",
      "  Name     Age            Email\n",
      "1  Bob  Thirty  bob@example.com\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data with some type issues (age has a string value)\n",
    "data = {\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"],\n",
    "    \"Age\": [25, \"Thirty\", 30, 22],  # Note: \"Thirty\" is invalid\n",
    "    \"Email\": [\"alice@example.com\", \"bob@example.com\", \"charlie@example.com\", \"david@example.com\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Expected types per column\n",
    "expected_types = {\n",
    "    \"Name\": str,\n",
    "    \"Age\": int,\n",
    "    \"Email\": str\n",
    "}\n",
    "\n",
    "def check_dtype(value, expected_type):\n",
    "    try:\n",
    "        # For int, float etc., try to cast\n",
    "        if expected_type == int:\n",
    "            int(value)\n",
    "        elif expected_type == float:\n",
    "            float(value)\n",
    "        elif expected_type == str:\n",
    "            str(value)\n",
    "        else:\n",
    "            return False\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Validate each cell against expected type\n",
    "type_validation = pd.DataFrame()\n",
    "for col, exp_type in expected_types.items():\n",
    "    type_validation[col] = df[col].apply(lambda x: check_dtype(x, exp_type))\n",
    "\n",
    "print(\"Data Type Validity per Cell (True=valid, False=invalid):\")\n",
    "print(type_validation)\n",
    "\n",
    "# Rows with any invalid data type\n",
    "invalid_rows = type_validation[~type_validation.all(axis=1)]\n",
    "print(\"\\nRows with Invalid Data Types:\")\n",
    "print(df.loc[invalid_rows.index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3**: Verify Uniqueness of Identifiers\n",
    "\n",
    "**Description**: Check if a dataset has unique identifiers (e.g., emails)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is 'Email' column unique? False\n",
      "\n",
      "Duplicate Emails Found:\n",
      "      Name              Email\n",
      "0    Alice  alice@example.com\n",
      "2  Charlie  alice@example.com\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data with duplicate emails\n",
    "data = {\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"],\n",
    "    \"Email\": [\"alice@example.com\", \"bob@example.com\", \"alice@example.com\", \"david@example.com\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check if 'Email' column has unique values\n",
    "is_unique = df[\"Email\"].is_unique\n",
    "\n",
    "print(f\"Is 'Email' column unique? {is_unique}\")\n",
    "\n",
    "if not is_unique:\n",
    "    # Find duplicated emails\n",
    "    duplicates = df[df[\"Email\"].duplicated(keep=False)]\n",
    "    print(\"\\nDuplicate Emails Found:\")\n",
    "    print(duplicates)\n",
    "else:\n",
    "    print(\"\\nNo duplicates found in 'Email' column.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4: Validate Email Format Using Regex\n",
    "\n",
    "Description: Validate if email addresses in a dataset have the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name              Email  Email_Valid\n",
      "0    Alice  alice@example.com         True\n",
      "1      Bob    bob.example.com        False\n",
      "2  Charlie    charlie@example        False\n",
      "3    David  david@example.com         True\n",
      "\n",
      "Invalid Email Addresses:\n",
      "      Name            Email\n",
      "1      Bob  bob.example.com\n",
      "2  Charlie  charlie@example\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Sample data with valid and invalid emails\n",
    "data = {\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"],\n",
    "    \"Email\": [\"alice@example.com\", \"bob.example.com\", \"charlie@example\", \"david@example.com\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Simple regex pattern for email validation\n",
    "email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n",
    "\n",
    "# Function to validate emails using regex\n",
    "def validate_email(email):\n",
    "    if re.match(email_pattern, email):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Apply validation\n",
    "df['Email_Valid'] = df['Email'].apply(validate_email)\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Show invalid emails\n",
    "invalid_emails = df[~df['Email_Valid']]\n",
    "print(\"\\nInvalid Email Addresses:\")\n",
    "print(invalid_emails[['Name', 'Email']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5: Check for Logical Age Validity\n",
    "\n",
    "Description: Ensure ages are within a reasonable human range (e.g., 0-120)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age  Age_Valid\n",
      "0    Alice   25       True\n",
      "1      Bob   -5      False\n",
      "2  Charlie  130      False\n",
      "3    David   45       True\n",
      "\n",
      "Records with Invalid Age:\n",
      "      Name  Age  Age_Valid\n",
      "1      Bob   -5      False\n",
      "2  Charlie  130      False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data with some invalid ages\n",
    "data = {\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"],\n",
    "    \"Age\": [25, -5, 130, 45]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define valid age range\n",
    "min_age = 0\n",
    "max_age = 120\n",
    "\n",
    "# Check which ages are valid\n",
    "df['Age_Valid'] = df['Age'].between(min_age, max_age)\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Display invalid age records\n",
    "invalid_ages = df[~df['Age_Valid']]\n",
    "print(\"\\nRecords with Invalid Age:\")\n",
    "print(invalid_ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 6: Identify and Handle Missing Data\n",
    "\n",
    "Description: Identify missing values in a dataset and impute them using a simple strategy (e.g., mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "      Name   Age   Salary\n",
      "0    Alice  25.0  50000.0\n",
      "1      Bob   NaN  60000.0\n",
      "2  Charlie  30.0      NaN\n",
      "3    David  45.0  80000.0\n",
      "4      Eva   NaN  70000.0\n",
      "\n",
      "Missing values per column:\n",
      "Name      0\n",
      "Age       2\n",
      "Salary    1\n",
      "dtype: int64\n",
      "\n",
      "Data after mean imputation:\n",
      "      Name        Age   Salary\n",
      "0    Alice  25.000000  50000.0\n",
      "1      Bob  33.333333  60000.0\n",
      "2  Charlie  30.000000  65000.0\n",
      "3    David  45.000000  80000.0\n",
      "4      Eva  33.333333  70000.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample data with missing values\n",
    "data = {\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\"],\n",
    "    \"Age\": [25, np.nan, 30, 45, np.nan],\n",
    "    \"Salary\": [50000, 60000, np.nan, 80000, 70000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(df)\n",
    "\n",
    "# Step 1: Detect missing values\n",
    "missing_counts = df.isnull().sum()\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(missing_counts)\n",
    "\n",
    "# Step 2: Impute missing numerical values using mean\n",
    "# For simplicity, we impute only numeric columns\n",
    "numeric_cols = df.select_dtypes(include='number').columns\n",
    "\n",
    "for col in numeric_cols:\n",
    "    mean_value = df[col].mean()\n",
    "    df[col].fillna(mean_value, inplace=True)\n",
    "\n",
    "print(\"\\nData after mean imputation:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 7: Detect Duplicates\n",
    "\n",
    "Description: Detect duplicate rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "      Name  Age  Salary\n",
      "0    Alice   25   50000\n",
      "1      Bob   30   60000\n",
      "2  Charlie   35   70000\n",
      "3    Alice   25   50000\n",
      "4      Bob   30   60000\n",
      "\n",
      "Duplicate Rows:\n",
      "    Name  Age  Salary\n",
      "0  Alice   25   50000\n",
      "1    Bob   30   60000\n",
      "3  Alice   25   50000\n",
      "4    Bob   30   60000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data with duplicates\n",
    "data = {\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"Alice\", \"Bob\"],\n",
    "    \"Age\": [25, 30, 35, 25, 30],\n",
    "    \"Salary\": [50000, 60000, 70000, 50000, 60000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(df)\n",
    "\n",
    "# Detect duplicate rows\n",
    "duplicates = df.duplicated(keep=False)  # mark all duplicates as True\n",
    "\n",
    "print(\"\\nDuplicate Rows:\")\n",
    "print(df[duplicates])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 8: Validate Correctness of Numerical Values\n",
    "\n",
    "Description: Ensure numerical columns are within a specified range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "      Name  Age  Salary\n",
      "0    Alice   25   50000\n",
      "1      Bob   -5   60000\n",
      "2  Charlie  130   70000\n",
      "3    David   40   -1000\n",
      "\n",
      "Invalid values in column 'Age':\n",
      "      Name  Age  Salary\n",
      "1      Bob   -5   60000\n",
      "2  Charlie  130   70000\n",
      "\n",
      "Invalid values in column 'Salary':\n",
      "    Name  Age  Salary\n",
      "3  David   40   -1000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"],\n",
    "    \"Age\": [25, -5, 130, 40],   # -5 and 130 are invalid ages\n",
    "    \"Salary\": [50000, 60000, 70000, -1000]  # -1000 invalid salary\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(df)\n",
    "\n",
    "# Define valid ranges for numerical columns\n",
    "valid_ranges = {\n",
    "    \"Age\": (0, 120),\n",
    "    \"Salary\": (0, None)  # None means no upper limit\n",
    "}\n",
    "\n",
    "# Check validity for each column\n",
    "for col, (min_val, max_val) in valid_ranges.items():\n",
    "    if min_val is not None:\n",
    "        invalid_low = df[col] < min_val\n",
    "    else:\n",
    "        invalid_low = pd.Series([False] * len(df))\n",
    "        \n",
    "    if max_val is not None:\n",
    "        invalid_high = df[col] > max_val\n",
    "    else:\n",
    "        invalid_high = pd.Series([False] * len(df))\n",
    "        \n",
    "    invalid = invalid_low | invalid_high\n",
    "    \n",
    "    print(f\"\\nInvalid values in column '{col}':\")\n",
    "    print(df[invalid])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 9: Custom Completeness Rule Violation Report\n",
    "\n",
    "Description: Create a report showing which rows violate specific completeness rules, such as mandatory fields being empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Completeness Rule Violation Report:\n",
      "      Name              Email       Phone  Age Missing Fields\n",
      "1     None    bob@example.com        None   30    Name, Phone\n",
      "2  Charlie               None  9876543210   35          Email\n",
      "3    David  david@example.com               40          Phone\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data with missing mandatory fields\n",
    "data = {\n",
    "    \"Name\": [\"Alice\", None, \"Charlie\", \"David\"],\n",
    "    \"Email\": [\"alice@example.com\", \"bob@example.com\", None, \"david@example.com\"],\n",
    "    \"Phone\": [\"1234567890\", None, \"9876543210\", \"\"],\n",
    "    \"Age\": [25, 30, 35, 40]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define mandatory fields\n",
    "mandatory_fields = [\"Name\", \"Email\", \"Phone\"]\n",
    "\n",
    "# Create a boolean mask for rows violating completeness (missing mandatory fields)\n",
    "violations_mask = df[mandatory_fields].isnull() | (df[mandatory_fields] == \"\")\n",
    "\n",
    "# Identify rows where any mandatory field is missing or empty\n",
    "rows_with_violations = violations_mask.any(axis=1)\n",
    "\n",
    "# Filter rows that violate completeness rules\n",
    "violation_report = df[rows_with_violations].copy()\n",
    "\n",
    "# For clarity, add a summary column listing which mandatory fields are missing per row\n",
    "def list_missing_fields(row):\n",
    "    missing = []\n",
    "    for field in mandatory_fields:\n",
    "        if pd.isnull(row[field]) or row[field] == \"\":\n",
    "            missing.append(field)\n",
    "    return \", \".join(missing)\n",
    "\n",
    "violation_report[\"Missing Fields\"] = violation_report.apply(list_missing_fields, axis=1)\n",
    "\n",
    "print(\"Custom Completeness Rule Violation Report:\")\n",
    "print(violation_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 10: Advanced Regex for Data Validity Check\n",
    "\n",
    "Description: Check for validity with advanced regex patterns, such as validating complex fields with multi-level rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Product_Code  Is_Valid\n",
      "0     ABC-1234      True\n",
      "1   XYZ-5678-X      True\n",
      "2   DEF-0000-Y      True\n",
      "3     abc-1234     False\n",
      "4    ABCD-1234     False\n",
      "5    XYZ-56789     False\n",
      "6   XYZ-5678-Z     False\n",
      "7      XY-5678     False\n",
      "8      ABC1234     False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Sample dataset with product codes\n",
    "data = {\n",
    "    \"Product_Code\": [\n",
    "        \"ABC-1234\",    # valid\n",
    "        \"XYZ-5678-X\",  # valid\n",
    "        \"DEF-0000-Y\",  # valid\n",
    "        \"abc-1234\",    # invalid (lowercase letters)\n",
    "        \"ABCD-1234\",   # invalid (4 letters instead of 3)\n",
    "        \"XYZ-56789\",   # invalid (5 digits instead of 4)\n",
    "        \"XYZ-5678-Z\",  # invalid (suffix Z not allowed)\n",
    "        \"XY-5678\",     # invalid (only 2 letters)\n",
    "        \"ABC1234\"      # invalid (missing hyphen)\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define advanced regex pattern\n",
    "pattern = r'^[A-Z]{3}-\\d{4}(-[XY])?$'\n",
    "\n",
    "# Function to check validity using regex\n",
    "def check_product_code_validity(code):\n",
    "    if re.match(pattern, code):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Apply validation\n",
    "df[\"Is_Valid\"] = df[\"Product_Code\"].apply(check_product_code_validity)\n",
    "\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
