{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "      Sex\n",
      "0    male\n",
      "1  female\n",
      "2  female\n",
      "3    male\n",
      "4    male\n",
      "\n",
      "After Label Encoding:\n",
      "      Sex  Sex_LabelEncoded\n",
      "0    male                 1\n",
      "1  female                 0\n",
      "2  female                 0\n",
      "3    male                 1\n",
      "4    male                 1\n",
      "\n",
      "One-Hot Encoded Columns:\n",
      "   Sex_female  Sex_male\n",
      "0       False      True\n",
      "1        True     False\n",
      "2        True     False\n",
      "3       False      True\n",
      "4       False      True\n",
      "\n",
      "DataFrame with One-Hot Encoding:\n",
      "      Sex  Sex_LabelEncoded  Sex_female  Sex_male\n",
      "0    male                 1       False      True\n",
      "1  female                 0        True     False\n",
      "2  female                 0        True     False\n",
      "3    male                 1       False      True\n",
      "4    male                 1       False      True\n",
      "Standardized Data (mean ~ 0, std ~ 1):\n",
      "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
      "count       1.500000e+02      1.500000e+02       1.500000e+02   \n",
      "mean       -1.468455e-15     -1.823726e-15      -1.610564e-15   \n",
      "std         1.003350e+00      1.003350e+00       1.003350e+00   \n",
      "min        -1.870024e+00     -2.433947e+00      -1.567576e+00   \n",
      "25%        -9.006812e-01     -5.923730e-01      -1.226552e+00   \n",
      "50%        -5.250608e-02     -1.319795e-01       3.364776e-01   \n",
      "75%         6.745011e-01      5.586108e-01       7.627583e-01   \n",
      "max         2.492019e+00      3.090775e+00       1.785832e+00   \n",
      "\n",
      "       petal width (cm)  \n",
      "count      1.500000e+02  \n",
      "mean      -9.473903e-16  \n",
      "std        1.003350e+00  \n",
      "min       -1.447076e+00  \n",
      "25%       -1.183812e+00  \n",
      "50%        1.325097e-01  \n",
      "75%        7.906707e-01  \n",
      "max        1.712096e+00  \n",
      "\n",
      "Combined (Standardized + Min-Max Scaled to [0, 1]):\n",
      "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
      "count         150.000000        150.000000         150.000000   \n",
      "mean            0.428704          0.440556           0.467458   \n",
      "std             0.230018          0.181611           0.299203   \n",
      "min             0.000000          0.000000           0.000000   \n",
      "25%             0.222222          0.333333           0.101695   \n",
      "50%             0.416667          0.416667           0.567797   \n",
      "75%             0.583333          0.541667           0.694915   \n",
      "max             1.000000          1.000000           1.000000   \n",
      "\n",
      "       petal width (cm)  \n",
      "count        150.000000  \n",
      "mean           0.458056  \n",
      "std            0.317599  \n",
      "min            0.000000  \n",
      "25%            0.083333  \n",
      "50%            0.500000  \n",
      "75%            0.708333  \n",
      "max            1.000000  \n",
      "Original columns:\n",
      "      sex embarked\n",
      "0    male        S\n",
      "1  female        C\n",
      "2  female        S\n",
      "3  female        S\n",
      "4    male        S\n",
      "\n",
      "One-Hot Encoded columns:\n",
      "   sex_male  embarked_Q  embarked_S  embarked_missing\n",
      "0      True       False        True             False\n",
      "1     False       False       False             False\n",
      "2     False       False        True             False\n",
      "3     False       False        True             False\n",
      "4      True       False        True             False\n",
      "Original 'Pclass' column:\n",
      "pclass\n",
      "1    216\n",
      "2    184\n",
      "3    491\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Ordinal Encoded 'Pclass':\n",
      "   pclass  pclass_encoded\n",
      "0       3               2\n",
      "1       1               0\n",
      "2       3               2\n",
      "3       1               0\n",
      "4       3               2\n",
      "  Scaling Technique  Decision Tree Accuracy  SVM Accuracy\n",
      "0              None                     1.0           1.0\n",
      "1   Min-Max Scaling                     1.0           1.0\n",
      "2   Standardization                     1.0           1.0\n",
      "  user_id  purchase_amount  user_id_encoded\n",
      "0      U1              100              0.3\n",
      "1      U2              150              0.3\n",
      "2      U3              200              0.2\n",
      "3      U2              130              0.3\n",
      "4      U1              180              0.3\n",
      "5      U4               90              0.1\n",
      "6      U2              160              0.3\n",
      "7      U5              110              0.1\n",
      "8      U3              170              0.2\n",
      "9      U1              120              0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17992/3517376159.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pclass_df['pclass'] = pclass_df['pclass'].astype(str)  # Encoding needs strings\n"
     ]
    }
   ],
   "source": [
    "# Question 5: Label Encoding vs One-Hot Encoding\n",
    "# Task: Show the difference between Label Encoding and One-Hot Encoding on the Titanic dataset for the 'Sex' feature.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Sample 'Sex' column from Titanic dataset\n",
    "data = {'Sex': ['male', 'female', 'female', 'male', 'male']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(df)\n",
    "\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df['Sex_LabelEncoded'] = label_encoder.fit_transform(df['Sex'])\n",
    "\n",
    "print(\"\\nAfter Label Encoding:\")\n",
    "print(df)\n",
    "\n",
    "# One-Hot Encoding using pandas get_dummies\n",
    "df_onehot = pd.get_dummies(df['Sex'], prefix='Sex')\n",
    "\n",
    "print(\"\\nOne-Hot Encoded Columns:\")\n",
    "print(df_onehot)\n",
    "\n",
    "# Combine original df with one-hot columns\n",
    "df = pd.concat([df, df_onehot], axis=1)\n",
    "print(\"\\nDataFrame with One-Hot Encoding:\")\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 6: Combining Feature Scaling Techniques\n",
    "# Task: Demonstrate combining Min-Max Scaling and Standardization for the same datasetand explain the results.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "feature_names = iris.feature_names\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "\n",
    "# Step 1: Standardization\n",
    "scaler_standard = StandardScaler()\n",
    "X_standardized = scaler_standard.fit_transform(df)\n",
    "df_standardized = pd.DataFrame(X_standardized, columns=feature_names)\n",
    "\n",
    "# Step 2: Min-Max Scaling after Standardization\n",
    "scaler_minmax = MinMaxScaler()\n",
    "X_scaled_combined = scaler_minmax.fit_transform(df_standardized)\n",
    "df_scaled_combined = pd.DataFrame(X_scaled_combined, columns=feature_names)\n",
    "\n",
    "# Output summary\n",
    "print(\"Standardized Data (mean ~ 0, std ~ 1):\")\n",
    "print(df_standardized.describe())\n",
    "\n",
    "print(\"\\nCombined (Standardized + Min-Max Scaled to [0, 1]):\")\n",
    "print(df_scaled_combined.describe())\n",
    "\n",
    "\n",
    "# Question 7: Handling Multiple Categorical Features\n",
    "# Task: Handle multiple categorical features ('Sex', 'Embarked') from the Titanic dataset using One-Hot Encoding.\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Load Titanic dataset\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# Display original columns\n",
    "print(\"Original columns:\")\n",
    "print(df[['sex', 'embarked']].head())\n",
    "\n",
    "# Handle missing values in 'embarked' (if any)\n",
    "df['embarked'].fillna('missing', inplace=True)\n",
    "\n",
    "# Apply One-Hot Encoding to 'sex' and 'embarked'\n",
    "df_encoded = pd.get_dummies(df, columns=['sex', 'embarked'], drop_first=True)\n",
    "\n",
    "# Display resulting columns\n",
    "print(\"\\nOne-Hot Encoded columns:\")\n",
    "print(df_encoded.filter(regex='sex_|embarked_').head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 8: Ordinal Encoding for Ranked Categories\n",
    "# Task: Ordinal encode 'Pclass' (Passenger class) from the Titanic dataset considering passenger class as a ranked feature.\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Load Titanic dataset\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# Check original Pclass values\n",
    "print(\"Original 'Pclass' column:\")\n",
    "print(df['pclass'].value_counts().sort_index())\n",
    "\n",
    "# Convert to DataFrame for encoder compatibility\n",
    "pclass_df = df[['pclass']]\n",
    "\n",
    "# Optional: make sure it's treated as categorical\n",
    "pclass_df['pclass'] = pclass_df['pclass'].astype(str)  # Encoding needs strings\n",
    "\n",
    "# Define Ordinal Encoder with custom order (optional, but shows intent clearly)\n",
    "encoder = OrdinalEncoder(categories=[['1', '2', '3']])  # '1' is highest class\n",
    "pclass_encoded = encoder.fit_transform(pclass_df)\n",
    "\n",
    "# Add back to DataFrame\n",
    "df['pclass_encoded'] = pclass_encoded.astype(int)\n",
    "\n",
    "# Show result\n",
    "print(\"\\nOrdinal Encoded 'Pclass':\")\n",
    "print(df[['pclass', 'pclass_encoded']].head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 9: Impact of Scaling on Different Algorithms\n",
    "# Task: Investigate the impact of different scaling techniques on a decision tree model and compare it with a SVM.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define scalers\n",
    "scalers = {\n",
    "    'None': None,\n",
    "    'Min-Max Scaling': MinMaxScaler(),\n",
    "    'Standardization': StandardScaler()\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "for scale_name, scaler in scalers.items():\n",
    "    if scaler is not None:\n",
    "        scaler.fit(X_train)\n",
    "        X_train_scaled = scaler.transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "    else:\n",
    "        X_train_scaled, X_test_scaled = X_train, X_test\n",
    "\n",
    "    # Decision Tree\n",
    "    dt = DecisionTreeClassifier(random_state=42)\n",
    "    dt.fit(X_train_scaled, y_train)\n",
    "    dt_acc = accuracy_score(y_test, dt.predict(X_test_scaled))\n",
    "\n",
    "    # SVM\n",
    "    svm = SVC(random_state=42)\n",
    "    svm.fit(X_train_scaled, y_train)\n",
    "    svm_acc = accuracy_score(y_test, svm.predict(X_test_scaled))\n",
    "\n",
    "    results.append((scale_name, dt_acc, svm_acc))\n",
    "\n",
    "# Display results\n",
    "df_results = pd.DataFrame(results, columns=['Scaling Technique', 'Decision Tree Accuracy', 'SVM Accuracy'])\n",
    "print(df_results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 10: Custom Transformations for Categorical Features\n",
    "# Task: Implement a custom transformation function for encoding high cardinality categorical features efficiently.\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data with high cardinality categorical column\n",
    "df = pd.DataFrame({\n",
    "    'user_id': ['U1', 'U2', 'U3', 'U2', 'U1', 'U4', 'U2', 'U5', 'U3', 'U1'],\n",
    "    'purchase_amount': [100, 150, 200, 130, 180, 90, 160, 110, 170, 120]\n",
    "})\n",
    "\n",
    "# Custom frequency encoding function\n",
    "def frequency_encode(column):\n",
    "    freq = column.value_counts() / len(column)\n",
    "    return column.map(freq)\n",
    "\n",
    "# Apply transformation\n",
    "df['user_id_encoded'] = frequency_encode(df['user_id'])\n",
    "\n",
    "# Display result\n",
    "print(df)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
