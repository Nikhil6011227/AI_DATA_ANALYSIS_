{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automating Data Cleaning in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "    Task: Basic Pipeline with Scaling\n",
    "1. Objective: Create a pipeline that scales numerical features in a dataset.\n",
    "2. Steps:\n",
    "    - Load a sample dataset with Pandas.\n",
    "    - Define a pipeline using Pipeline from sklearn.pipeline .\n",
    "    - Use StandardScaler to scale features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0          -0.900681          1.019004          -1.340227         -1.315444\n",
      "1          -1.143017         -0.131979          -1.340227         -1.315444\n",
      "2          -1.385353          0.328414          -1.397064         -1.315444\n",
      "3          -1.506521          0.098217          -1.283389         -1.315444\n",
      "4          -1.021849          1.249201          -1.340227         -1.315444\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "# Step 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Step 2: Load a sample dataset\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "# Step 3: Define a pipeline\n",
    "scaling_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Step 4: Fit and transform the data using the pipeline\n",
    "scaled_data = scaling_pipeline.fit_transform(df)\n",
    "\n",
    "# Step 5: Convert result to DataFrame for readability\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=iris.feature_names)\n",
    "print(scaled_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Task: Pipeline with Imputation\n",
    "1. Objective: Automate data cleaning by handling missing values.\n",
    "2. Steps:\n",
    "    - Load a dataset with missing values.\n",
    "    - Define a pipeline to use SimpleImputer for filling missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Imputation:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                5.1               3.5                1.4               0.2\n",
      "1                4.9               3.0                1.4               0.2\n",
      "2                4.7               3.2                1.3               0.2\n",
      "3                4.6               3.1                NaN               NaN\n",
      "4                NaN               3.6                1.4               0.2\n",
      "\n",
      "After Imputation:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0           5.100000               3.5           1.400000          0.200000\n",
      "1           4.900000               3.0           1.400000          0.200000\n",
      "2           4.700000               3.2           1.300000          0.200000\n",
      "3           4.600000               3.1           3.779699          1.207087\n",
      "4           5.791304               3.6           1.400000          0.200000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Load Iris data into a DataFrame\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "\n",
    "# Introduce some missing values randomly for testing\n",
    "np.random.seed(0)\n",
    "missing_mask = np.random.rand(*df.shape) < 0.1  # 10% missing\n",
    "df = df.mask(missing_mask)\n",
    "\n",
    "print(\"Before Imputation:\")\n",
    "print(df.head())\n",
    "\n",
    "# Define pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "df[numerical_columns] = pipeline.fit_transform(df[numerical_columns])\n",
    "\n",
    "print(\"\\nAfter Imputation:\")\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
