{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (7, 4)\n",
      "Original dataset:\n",
      "   CustomerID     Name                Email  PurchaseAmount\n",
      "0         101    Alice    alice@example.com             250\n",
      "1         102      Bob      bob@example.com             150\n",
      "2         103  Charlie  charlie@example.com             200\n",
      "3         101    Alice    alice@example.com             250\n",
      "4         104    David    david@example.com             300\n",
      "5         105      Eva      eva@example.com             450\n",
      "6         103  Charlie  charlie@example.com             200\n",
      "\n",
      "Duplicate rows identified (True means duplicate):\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "4    False\n",
      "5    False\n",
      "6     True\n",
      "dtype: bool\n",
      "\n",
      "Dataset shape after removing duplicates: (5, 4)\n",
      "Dataset after removing duplicates:\n",
      "   CustomerID     Name                Email  PurchaseAmount\n",
      "0         101    Alice    alice@example.com             250\n",
      "1         102      Bob      bob@example.com             150\n",
      "2         103  Charlie  charlie@example.com             200\n",
      "4         104    David    david@example.com             300\n",
      "5         105      Eva      eva@example.com             450\n",
      "\n",
      "Number of duplicate rows removed: 2\n",
      "\n",
      "Duplicate data means the same record appears multiple times.\n",
      "This can skew the analysis by giving more weight to repeated records,\n",
      "leading models to overfit or bias predictions toward duplicated instances.\n",
      "Removing duplicates ensures the model learns from unique data points,\n",
      "improving prediction accuracy and generalization.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample dataset with duplicates\n",
    "data = {\n",
    "    'CustomerID': [101, 102, 103, 101, 104, 105, 103],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'David', 'Eva', 'Charlie'],\n",
    "    'Email': ['alice@example.com', 'bob@example.com', 'charlie@example.com', 'alice@example.com', 'david@example.com', 'eva@example.com', 'charlie@example.com'],\n",
    "    'PurchaseAmount': [250, 150, 200, 250, 300, 450, 200]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original dataset shape:\", df.shape)\n",
    "print(\"Original dataset:\")\n",
    "print(df)\n",
    "\n",
    "# Task 1: Identify duplicate entries\n",
    "duplicates = df.duplicated()\n",
    "print(\"\\nDuplicate rows identified (True means duplicate):\")\n",
    "print(duplicates)\n",
    "\n",
    "# Task 2: Remove duplicate entries\n",
    "df_cleaned = df.drop_duplicates()\n",
    "\n",
    "print(\"\\nDataset shape after removing duplicates:\", df_cleaned.shape)\n",
    "print(\"Dataset after removing duplicates:\")\n",
    "print(df_cleaned)\n",
    "\n",
    "# Optional: Count duplicates\n",
    "num_duplicates = duplicates.sum()\n",
    "print(f\"\\nNumber of duplicate rows removed: {num_duplicates}\")\n",
    "\n",
    "# Task 3: Explanation for classmate\n",
    "explanation = \"\"\"\n",
    "Duplicate data means the same record appears multiple times.\n",
    "This can skew the analysis by giving more weight to repeated records,\n",
    "leading models to overfit or bias predictions toward duplicated instances.\n",
    "Removing duplicates ensures the model learns from unique data points,\n",
    "improving prediction accuracy and generalization.\n",
    "\"\"\"\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  ID    Age Salary\n",
      "0  1     25  50000\n",
      "1  2     30  60000\n",
      "2  3     35   None\n",
      "3  4  forty  70000\n",
      "\n",
      "Data types before conversion:\n",
      "ID        object\n",
      "Age       object\n",
      "Salary    object\n",
      "dtype: object\n",
      "\n",
      "DataFrame after type conversion:\n",
      "   ID   Age   Salary\n",
      "0   1  25.0  50000.0\n",
      "1   2  30.0  60000.0\n",
      "2   3  35.0      NaN\n",
      "3   4   NaN  70000.0\n",
      "\n",
      "Data types after conversion:\n",
      "ID          int64\n",
      "Age       float64\n",
      "Salary    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data with inconsistent types\n",
    "data = {\n",
    "    'ID': ['1', '2', '3', '4'],\n",
    "    'Age': ['25', '30', '35', 'forty'],  # 'forty' is a non-numeric string\n",
    "    'Salary': ['50000', '60000', None, '70000'],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nData types before conversion:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Task 1: Convert 'ID' column to integers\n",
    "df['ID'] = pd.to_numeric(df['ID'], errors='coerce')\n",
    "\n",
    "# Task 2: Identify columns with inconsistent data types and convert where possible\n",
    "# Convert 'Age' and 'Salary' to numeric, coercing errors to NaN\n",
    "df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
    "df['Salary'] = pd.to_numeric(df['Salary'], errors='coerce')\n",
    "\n",
    "print(\"\\nDataFrame after type conversion:\")\n",
    "print(df)\n",
    "print(\"\\nData types after conversion:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Task 3: Discussion (as a comment)\n",
    "# Correct data types are critical for feature engineering because:\n",
    "# - Numerical operations require numeric types.\n",
    "# - ML algorithms need consistent input types.\n",
    "# - Incorrect types can cause errors or misleading analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1903437107.py, line 62)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[12], line 62\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"\"\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sample dataset with outliers\n",
    "data = {\n",
    "    'Age': [25, 30, 28, 22, 35, 150, 29, 27, 26, 28],  # 150 is an outlier\n",
    "    'Salary': [50000, 60000, 55000, 48000, 62000, 1000000, 58000, 59000, 61000, 57000]  # 1,000,000 is an outlier\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Task 1: Visualize outliers using boxplots\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(y=df['Age'])\n",
    "plt.title('Boxplot of Age')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=df['Salary'])\n",
    "plt.title('Boxplot of Salary')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Task 2: Remove or adjust outliers\n",
    "# Using the IQR method to identify outliers\n",
    "def remove_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    filtered_df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return filtered_df\n",
    "\n",
    "# Remove outliers from Age and Salary columns separately and then combine\n",
    "df_no_outliers_age = remove_outliers_iqr(df, 'Age')\n",
    "df_no_outliers_salary = remove_outliers_iqr(df, 'Salary')\n",
    "\n",
    "# Intersection of both filters to remove all outliers in either column\n",
    "df_no_outliers = df.loc[df.index.isin(df_no_outliers_age.index) & df.index.isin(df_no_outliers_salary.index)]\n",
    "\n",
    "print(\"\\nOriginal dataset shape:\", df.shape)\n",
    "print(\"Dataset shape after outlier removal:\", df_no_outliers.shape)\n",
    "\n",
    "# Visualize again after removing outliers\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(y=df_no_outliers['Age'])\n",
    "plt.title('Age without Outliers')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=df_no_outliers['Salary'])\n",
    "plt.title('Salary without Outliers')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Task 3: Research report on outlier handling techniques:\n",
    "\"\"\"\n",
    "Common techniques for handling outliers include:\n",
    "\n",
    "1. Removal: Simply remove the outlier data points if they are errors or irrelevant.\n",
    "2. Transformation: Apply transformations like log, square root to reduce skewness.\n",
    "3. Capping/Flooring (Winsorizing): Replace outliers with nearest acceptable values.\n",
    "4. Imputation: Replace outliers with mean, median, or predicted values.\n",
    "5. Robust models: Use algorithms that are less sensitive to outliers (e.g., tree-based models).\n",
    "\n",
    "Choice depends on the context and domain knowledge."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
