{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Understanding and Defining Data Quality Metrics\n",
    "**Description**: Learn how to define basic data quality metrics such as completeness, validity, and uniqueness for a simple dataset.\n",
    "\n",
    "**Steps**:\n",
    "1. Dataset: Use a CSV with columns like Name , Email , Age .\n",
    "2. Metric Definitions:\n",
    "    - Completeness: Percentage of non-null values.\n",
    "    - Validity: % of email fields containing @ .\n",
    "    - Uniqueness: Count distinct entries in the Email column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Data Quality Metrics\n",
      "------------------------\n",
      "Completeness (% per column):\n",
      " Name     80.0\n",
      "Email    80.0\n",
      "Age      80.0\n",
      "dtype: float64\n",
      "\n",
      "Validity (% of valid emails): 75.00%\n",
      "Uniqueness (distinct email count): 4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample dataset (replace this with pd.read_csv('your_file.csv') for real data)\n",
    "data = {\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", None, \"Eve\"],\n",
    "    \"Email\": [\"alice@example.com\", \"bob@example.com\", \"invalid_email\", \"eve@example.com\", None],\n",
    "    \"Age\": [25, 30, None, 40, 22]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 1. Completeness: Percentage of non-null values per column\n",
    "def calculate_completeness(df):\n",
    "    completeness = df.notnull().mean() * 100\n",
    "    return completeness\n",
    "\n",
    "# 2. Validity: % of emails containing '@'\n",
    "def calculate_email_validity(df):\n",
    "    valid_emails = df[\"Email\"].dropna().apply(lambda x: \"@\" in x)\n",
    "    validity_percentage = valid_emails.mean() * 100\n",
    "    return validity_percentage\n",
    "\n",
    "# 3. Uniqueness: Count of distinct emails\n",
    "def calculate_email_uniqueness(df):\n",
    "    unique_emails = df[\"Email\"].nunique(dropna=True)\n",
    "    return unique_emails\n",
    "\n",
    "# Running all metrics\n",
    "completeness = calculate_completeness(df)\n",
    "validity = calculate_email_validity(df)\n",
    "uniqueness = calculate_email_uniqueness(df)\n",
    "\n",
    "# Display Results\n",
    "print(\"üìä Data Quality Metrics\")\n",
    "print(\"------------------------\")\n",
    "print(\"Completeness (% per column):\\n\", completeness)\n",
    "print(f\"\\nValidity (% of valid emails): {validity:.2f}%\")\n",
    "print(f\"Uniqueness (distinct email count): {uniqueness}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Calculating Data Quality Score\n",
    "**Description**: Aggregate multiple metrics to calculate an overall data quality score.\n",
    "\n",
    "**Steps**:\n",
    "1. Formula: Simple average of all metrics defined in Task 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Data Quality Summary\n",
      "------------------------\n",
      "Completeness (%): 80.0%\n",
      "Validity (%): 75.0%\n",
      "Uniqueness (%): 100.0%\n",
      "Data Quality Score (%): 85.0%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample dataset (replace with pd.read_csv('your_data.csv') for real-world use)\n",
    "data = {\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", None, \"Eve\"],\n",
    "    \"Email\": [\"alice@example.com\", \"bob@example.com\", \"invalid_email\", \"eve@example.com\", None],\n",
    "    \"Age\": [25, 30, None, 40, 22]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# --- Task 1 Metrics ---\n",
    "\n",
    "# 1. Completeness: % of non-null values per column\n",
    "def calculate_completeness(df):\n",
    "    return df.notnull().mean().mean() * 100  # Average completeness across all columns\n",
    "\n",
    "# 2. Validity: % of email fields containing '@'\n",
    "def calculate_email_validity(df):\n",
    "    valid_emails = df[\"Email\"].dropna().apply(lambda x: \"@\" in x)\n",
    "    return valid_emails.mean() * 100\n",
    "\n",
    "# 3. Uniqueness: % of unique email values\n",
    "def calculate_email_uniqueness(df):\n",
    "    total = df[\"Email\"].dropna().shape[0]\n",
    "    unique = df[\"Email\"].nunique(dropna=True)\n",
    "    return (unique / total * 100) if total else 0\n",
    "\n",
    "# --- Task 2: Aggregate all metrics into a Data Quality Score ---\n",
    "def calculate_data_quality_score(df):\n",
    "    completeness = calculate_completeness(df)\n",
    "    validity = calculate_email_validity(df)\n",
    "    uniqueness = calculate_email_uniqueness(df)\n",
    "    \n",
    "    # Simple average\n",
    "    score = (completeness + validity + uniqueness) / 3\n",
    "    return {\n",
    "        \"Completeness (%)\": round(completeness, 2),\n",
    "        \"Validity (%)\": round(validity, 2),\n",
    "        \"Uniqueness (%)\": round(uniqueness, 2),\n",
    "        \"Data Quality Score (%)\": round(score, 2)\n",
    "    }\n",
    "\n",
    "# Run\n",
    "result = calculate_data_quality_score(df)\n",
    "\n",
    "# Display results\n",
    "print(\"üìä Data Quality Summary\")\n",
    "print(\"------------------------\")\n",
    "for metric, value in result.items():\n",
    "    print(f\"{metric}: {value}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Creating Expectations for a CSV\n",
    "**Description**: Develop basic data quality expectations using Great Expectations.\n",
    "\n",
    "**Steps**:\n",
    "1. Expectation Suite\n",
    "2. Define Expectations for Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created sample 'data.csv' file.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'EphemeralDataContext' object has no attribute 'datasources'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 113\u001b[0m\n\u001b[1;32m    111\u001b[0m context \u001b[38;5;241m=\u001b[39m create_context()\n\u001b[1;32m    112\u001b[0m df \u001b[38;5;241m=\u001b[39m load_data()\n\u001b[0;32m--> 113\u001b[0m batch_request, suite_name \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_expectations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m validate_and_generate_report(context, batch_request, suite_name)\n\u001b[1;32m    115\u001b[0m dq_score \u001b[38;5;241m=\u001b[39m calculate_dq_score(df)\n",
      "Cell \u001b[0;32mIn[14], line 35\u001b[0m, in \u001b[0;36mcreate_expectations\u001b[0;34m(context, df)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# already exists\u001b[39;00m\n\u001b[1;32m     34\u001b[0m datasource_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_pandas_datasource\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datasource_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasources\u001b[49m:\n\u001b[1;32m     36\u001b[0m     context\u001b[38;5;241m.\u001b[39madd_datasource(\n\u001b[1;32m     37\u001b[0m         name\u001b[38;5;241m=\u001b[39mdatasource_name,\n\u001b[1;32m     38\u001b[0m         class_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasource\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m         }\n\u001b[1;32m     46\u001b[0m     )\n\u001b[1;32m     48\u001b[0m batch_request \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasource_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: datasource_name,\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_connector_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault_runtime_data_connector_name\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_identifiers\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault_identifier_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault_id\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     54\u001b[0m }\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EphemeralDataContext' object has no attribute 'datasources'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import great_expectations as gx\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Step 0: Create sample CSV data\n",
    "def create_sample_csv():\n",
    "    df = pd.DataFrame({\n",
    "        \"Name\": [\"Alice\", \"Bob\", \"Charlie\", None, \"Eve\"],\n",
    "        \"Email\": [\"alice@example.com\", \"bob@example.com\", \"invalid_email\", \"carol@example.com\", None],\n",
    "        \"Age\": [25, 30, None, 40, 22]\n",
    "    })\n",
    "    df.to_csv(\"data.csv\", index=False)\n",
    "    print(\"‚úÖ Created sample 'data.csv' file.\")\n",
    "\n",
    "# Step 1: Setup a minimal GE context\n",
    "def create_context():\n",
    "    context = gx.get_context()\n",
    "    return context\n",
    "\n",
    "# Step 2: Load the data\n",
    "def load_data():\n",
    "    df = pd.read_csv(\"data.csv\")\n",
    "    return df\n",
    "\n",
    "# Step 3: Create expectation suite\n",
    "def create_expectations(context, df):\n",
    "    suite_name = \"dq_suite\"\n",
    "    try:\n",
    "        context.create_expectation_suite(suite_name)\n",
    "    except:\n",
    "        pass  # already exists\n",
    "\n",
    "    datasource_name = \"my_pandas_datasource\"\n",
    "    if datasource_name not in context.datasources:\n",
    "        context.add_datasource(\n",
    "            name=datasource_name,\n",
    "            class_name=\"Datasource\",\n",
    "            execution_engine={\"class_name\": \"PandasExecutionEngine\"},\n",
    "            data_connectors={\n",
    "                \"default_runtime_data_connector_name\": {\n",
    "                    \"class_name\": \"RuntimeDataConnector\",\n",
    "                    \"batch_identifiers\": [\"default_identifier_name\"]\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "    batch_request = {\n",
    "        \"datasource_name\": datasource_name,\n",
    "        \"data_connector_name\": \"default_runtime_data_connector_name\",\n",
    "        \"data_asset_name\": \"my_data_asset\",\n",
    "        \"runtime_parameters\": {\"batch_data\": df},\n",
    "        \"batch_identifiers\": {\"default_identifier_name\": \"default_id\"}\n",
    "    }\n",
    "\n",
    "    validator = context.get_validator(batch_request=batch_request, expectation_suite_name=suite_name)\n",
    "\n",
    "    # Define basic expectations\n",
    "    validator.expect_column_values_to_not_be_null(\"Name\")\n",
    "    validator.expect_column_values_to_not_be_null(\"Email\")\n",
    "    validator.expect_column_values_to_not_be_null(\"Age\")\n",
    "    validator.expect_column_values_to_match_regex(\"Email\", regex=\".+@.+\\\\..+\")\n",
    "    validator.expect_column_values_to_be_unique(\"Email\")\n",
    "\n",
    "    validator.save_expectation_suite(discard_failed_expectations=False)\n",
    "\n",
    "    return batch_request, suite_name\n",
    "\n",
    "# Step 4: Validate and generate HTML report\n",
    "def validate_and_generate_report(context, batch_request, suite_name):\n",
    "    checkpoint = context.add_or_update_checkpoint(\n",
    "        name=\"dq_checkpoint\",\n",
    "        validations=[{\"batch_request\": batch_request, \"expectation_suite_name\": suite_name}]\n",
    "    )\n",
    "    results = checkpoint.run()\n",
    "    context.build_data_docs()\n",
    "    print(\"‚úÖ Validation complete. View the HTML report here:\")\n",
    "    print(context.get_docs_sites_urls()[0][\"site_url\"])\n",
    "\n",
    "# Step 5: Calculate Data Quality Score\n",
    "def calculate_dq_score(df):\n",
    "    completeness = df.notnull().mean().mean() * 100\n",
    "    validity = df[\"Email\"].dropna().apply(lambda x: \"@\" in x).mean() * 100\n",
    "    unique_email_count = df[\"Email\"].nunique(dropna=True)\n",
    "    total_email_rows = df[\"Email\"].dropna().shape[0]\n",
    "    uniqueness = (unique_email_count / total_email_rows * 100) if total_email_rows else 0\n",
    "    dq_score = (completeness + validity + uniqueness) / 3\n",
    "\n",
    "    print(\"\\nüìä Data Quality Metrics\")\n",
    "    print(f\"Completeness: {completeness:.2f}%\")\n",
    "    print(f\"Validity (Email): {validity:.2f}%\")\n",
    "    print(f\"Uniqueness (Email): {uniqueness:.2f}%\")\n",
    "    print(f\"üî¢ Final Data Quality Score: {dq_score:.2f}%\")\n",
    "\n",
    "    return dq_score\n",
    "\n",
    "# Step 6: Trigger data cleaning if quality score is low\n",
    "def clean_data(df):\n",
    "    print(\"\\n‚ö†Ô∏è Data Quality is low. Running cleaning script...\")\n",
    "    df_cleaned = df.copy()\n",
    "    df_cleaned = df_cleaned.dropna(subset=[\"Name\", \"Email\", \"Age\"])\n",
    "    df_cleaned = df_cleaned[df_cleaned[\"Email\"].str.contains(\"@\", na=False)]\n",
    "    print(\"‚úÖ Cleaned data:\")\n",
    "    print(df_cleaned)\n",
    "    df_cleaned.to_csv(\"cleaned_data.csv\", index=False)\n",
    "    print(\"üìÅ Saved cleaned data as 'cleaned_data.csv'\")\n",
    "\n",
    "# === MAIN EXECUTION ===\n",
    "if __name__ == \"__main__\":\n",
    "    create_sample_csv()\n",
    "    context = create_context()\n",
    "    df = load_data()\n",
    "    batch_request, suite_name = create_expectations(context, df)\n",
    "    validate_and_generate_report(context, batch_request, suite_name)\n",
    "    dq_score = calculate_dq_score(df)\n",
    "\n",
    "    # Threshold: 85%\n",
    "    if dq_score < 85:\n",
    "        clean_data(df)\n",
    "    else:\n",
    "        print(\"‚úÖ Data quality is acceptable. No cleaning needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Running and Validating Expectations\n",
    "**Description**: Run the created expectations and generate an output report.\n",
    "\n",
    "**Steps**:\n",
    "1. Validate\n",
    "2. Generate HTML Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: great_expectations in /home/vscode/.local/lib/python3.10/site-packages (1.4.4)\n",
      "Requirement already satisfied: pandas in /home/vscode/.local/lib/python3.10/site-packages (2.1.4)\n",
      "Requirement already satisfied: altair<5.0.0,>=4.2.1 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (4.2.2)\n",
      "Requirement already satisfied: cryptography>=3.2 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (45.0.2)\n",
      "Requirement already satisfied: jinja2>=3 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=2.5.1 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (4.23.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.7.1 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (3.26.1)\n",
      "Requirement already satisfied: mistune>=0.8.4 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (3.1.3)\n",
      "Requirement already satisfied: packaging in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (24.2)\n",
      "Requirement already satisfied: posthog<4,>3 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (3.25.0)\n",
      "Requirement already satisfied: pydantic>=1.10.7 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (2.11.4)\n",
      "Requirement already satisfied: pyparsing>=2.4 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (2.9.0.post0)\n",
      "Requirement already satisfied: requests>=2.20 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (2.32.3)\n",
      "Requirement already satisfied: ruamel.yaml>=0.16 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (0.18.10)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (1.15.2)\n",
      "Requirement already satisfied: tqdm>=4.59.0 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (4.13.2)\n",
      "Requirement already satisfied: tzlocal>=1.2 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/vscode/.local/lib/python3.10/site-packages (from great_expectations) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/vscode/.local/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/vscode/.local/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: entrypoints in /home/vscode/.local/lib/python3.10/site-packages (from altair<5.0.0,>=4.2.1->great_expectations) (0.4)\n",
      "Requirement already satisfied: toolz in /home/vscode/.local/lib/python3.10/site-packages (from altair<5.0.0,>=4.2.1->great_expectations) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/vscode/.local/lib/python3.10/site-packages (from posthog<4,>3->great_expectations) (1.17.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/vscode/.local/lib/python3.10/site-packages (from posthog<4,>3->great_expectations) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/vscode/.local/lib/python3.10/site-packages (from posthog<4,>3->great_expectations) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /home/vscode/.local/lib/python3.10/site-packages (from posthog<4,>3->great_expectations) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vscode/.local/lib/python3.10/site-packages (from requests>=2.20->great_expectations) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vscode/.local/lib/python3.10/site-packages (from requests>=2.20->great_expectations) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vscode/.local/lib/python3.10/site-packages (from requests>=2.20->great_expectations) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vscode/.local/lib/python3.10/site-packages (from requests>=2.20->great_expectations) (2025.4.26)\n",
      "Requirement already satisfied: cffi>=1.14 in /home/vscode/.local/lib/python3.10/site-packages (from cryptography>=3.2->great_expectations) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/vscode/.local/lib/python3.10/site-packages (from cffi>=1.14->cryptography>=3.2->great_expectations) (2.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/vscode/.local/lib/python3.10/site-packages (from jinja2>=3->great_expectations) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/vscode/.local/lib/python3.10/site-packages (from jsonschema>=2.5.1->great_expectations) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/vscode/.local/lib/python3.10/site-packages (from jsonschema>=2.5.1->great_expectations) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/vscode/.local/lib/python3.10/site-packages (from jsonschema>=2.5.1->great_expectations) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/vscode/.local/lib/python3.10/site-packages (from jsonschema>=2.5.1->great_expectations) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/vscode/.local/lib/python3.10/site-packages (from pydantic>=1.10.7->great_expectations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/vscode/.local/lib/python3.10/site-packages (from pydantic>=1.10.7->great_expectations) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/vscode/.local/lib/python3.10/site-packages (from pydantic>=1.10.7->great_expectations) (0.4.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /home/vscode/.local/lib/python3.10/site-packages (from ruamel.yaml>=0.16->great_expectations) (0.2.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "‚úÖ Sample CSV created.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'EphemeralDataContext' object has no attribute 'datasources'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 85\u001b[0m\n\u001b[1;32m     83\u001b[0m context \u001b[38;5;241m=\u001b[39m create_ge_context()\n\u001b[1;32m     84\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 85\u001b[0m batch_request, suite_name \u001b[38;5;241m=\u001b[39m \u001b[43mdefine_expectations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m validate_and_report(context, batch_request, suite_name)\n",
      "Cell \u001b[0;32mIn[9], line 29\u001b[0m, in \u001b[0;36mdefine_expectations\u001b[0;34m(context, df)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# If already created\u001b[39;00m\n\u001b[1;32m     28\u001b[0m datasource_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas_datasource\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datasource_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasources\u001b[49m:\n\u001b[1;32m     30\u001b[0m     context\u001b[38;5;241m.\u001b[39madd_datasource(\n\u001b[1;32m     31\u001b[0m         name\u001b[38;5;241m=\u001b[39mdatasource_name,\n\u001b[1;32m     32\u001b[0m         class_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasource\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m         }\n\u001b[1;32m     40\u001b[0m     )\n\u001b[1;32m     42\u001b[0m batch_request \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasource_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: datasource_name,\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_connector_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruntime_data_connector\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_identifiers\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_001\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     48\u001b[0m }\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EphemeralDataContext' object has no attribute 'datasources'"
     ]
    }
   ],
   "source": [
    "%pip install great_expectations pandas\n",
    "import pandas as pd\n",
    "import great_expectations as gx\n",
    "\n",
    "# Step 1: Create sample data\n",
    "def create_sample_data():\n",
    "    data = {\n",
    "        \"Name\": [\"Alice\", \"Bob\", \"Charlie\", None, \"Eve\"],\n",
    "        \"Email\": [\"alice@example.com\", \"bob@example.com\", \"invalid_email\", \"carol@example.com\", None],\n",
    "        \"Age\": [25, 30, None, 40, 22]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(\"data.csv\", index=False)\n",
    "    print(\"‚úÖ Sample CSV created.\")\n",
    "\n",
    "# Step 2: Load GE context\n",
    "def create_ge_context():\n",
    "    return gx.get_context()\n",
    "\n",
    "# Step 3: Create Expectations\n",
    "def define_expectations(context, df):\n",
    "    suite_name = \"basic_suite\"\n",
    "    try:\n",
    "        context.create_expectation_suite(suite_name)\n",
    "    except Exception:\n",
    "        pass  # If already created\n",
    "\n",
    "    datasource_name = \"pandas_datasource\"\n",
    "    if datasource_name not in context.datasources:\n",
    "        context.add_datasource(\n",
    "            name=datasource_name,\n",
    "            class_name=\"Datasource\",\n",
    "            execution_engine={\"class_name\": \"PandasExecutionEngine\"},\n",
    "            data_connectors={\n",
    "                \"runtime_data_connector\": {\n",
    "                    \"class_name\": \"RuntimeDataConnector\",\n",
    "                    \"batch_identifiers\": [\"default_id\"]\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "    batch_request = {\n",
    "        \"datasource_name\": datasource_name,\n",
    "        \"data_connector_name\": \"runtime_data_connector\",\n",
    "        \"data_asset_name\": \"my_data_asset\",\n",
    "        \"runtime_parameters\": {\"batch_data\": df},\n",
    "        \"batch_identifiers\": {\"default_id\": \"batch_001\"}\n",
    "    }\n",
    "\n",
    "    validator = context.get_validator(\n",
    "        batch_request=batch_request,\n",
    "        expectation_suite_name=suite_name\n",
    "    )\n",
    "\n",
    "    # Add some basic expectations\n",
    "    validator.expect_column_values_to_not_be_null(\"Name\")\n",
    "    validator.expect_column_values_to_match_regex(\"Email\", \".+@.+\\\\..+\")\n",
    "    validator.expect_column_values_to_not_be_null(\"Age\")\n",
    "    validator.expect_column_values_to_be_between(\"Age\", min_value=0, max_value=120)\n",
    "\n",
    "    validator.save_expectation_suite(discard_failed_expectations=False)\n",
    "    return batch_request, suite_name\n",
    "\n",
    "# Step 4: Run validation and generate report\n",
    "def validate_and_report(context, batch_request, suite_name):\n",
    "    checkpoint = context.add_or_update_checkpoint(\n",
    "        name=\"my_checkpoint\",\n",
    "        validations=[\n",
    "            {\n",
    "                \"batch_request\": batch_request,\n",
    "                \"expectation_suite_name\": suite_name\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    result = checkpoint.run()\n",
    "    context.build_data_docs()\n",
    "    print(\"üìÑ Validation complete. Report generated.\")\n",
    "    print(\"üîó Report location:\", context.get_docs_sites_urls()[0][\"site_url\"])\n",
    "\n",
    "# === MAIN ===\n",
    "if __name__ == \"__main__\":\n",
    "    create_sample_data()\n",
    "    context = create_ge_context()\n",
    "    df = pd.read_csv(\"data.csv\")\n",
    "    batch_request, suite_name = define_expectations(context, df)\n",
    "    validate_and_report(context, batch_request, suite_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Automating Data Quality Score Calculation\n",
    "**Description**: Automate the data quality score via a script that integrates with Great\n",
    "Expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EphemeralDataContext' object has no attribute 'datasources'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 91\u001b[0m\n\u001b[1;32m     89\u001b[0m df \u001b[38;5;241m=\u001b[39m create_sample_csv()\n\u001b[1;32m     90\u001b[0m context \u001b[38;5;241m=\u001b[39m get_ge_context()\n\u001b[0;32m---> 91\u001b[0m batch_request, suite_name \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_expectations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m calculate_data_quality_score(context, batch_request, suite_name)\n",
      "Cell \u001b[0;32mIn[10], line 27\u001b[0m, in \u001b[0;36mcreate_expectations\u001b[0;34m(context, df)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# already exists\u001b[39;00m\n\u001b[1;32m     26\u001b[0m datasource_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdq_datasource\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datasource_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasources\u001b[49m:\n\u001b[1;32m     28\u001b[0m     context\u001b[38;5;241m.\u001b[39madd_datasource(\n\u001b[1;32m     29\u001b[0m         name\u001b[38;5;241m=\u001b[39mdatasource_name,\n\u001b[1;32m     30\u001b[0m         class_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasource\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m         }\n\u001b[1;32m     38\u001b[0m     )\n\u001b[1;32m     40\u001b[0m batch_request \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasource_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: datasource_name,\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_connector_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruntime_data_connector\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_identifiers\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdq_batch_01\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     46\u001b[0m }\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EphemeralDataContext' object has no attribute 'datasources'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import great_expectations as gx\n",
    "\n",
    "# Step 1: Create sample data and load\n",
    "def create_sample_csv():\n",
    "    df = pd.DataFrame({\n",
    "        \"Name\": [\"Alice\", \"Bob\", None, \"David\", \"Eve\"],\n",
    "        \"Email\": [\"alice@example.com\", \"bob@example.com\", \"invalid_email\", None, \"eve@example.com\"],\n",
    "        \"Age\": [25, 30, None, 22, 45]\n",
    "    })\n",
    "    df.to_csv(\"data_quality_sample.csv\", index=False)\n",
    "    return df\n",
    "\n",
    "# Step 2: Setup Great Expectations context\n",
    "def get_ge_context():\n",
    "    return gx.get_context()\n",
    "\n",
    "# Step 3: Define Expectations\n",
    "def create_expectations(context, df):\n",
    "    suite_name = \"dq_score_suite\"\n",
    "    try:\n",
    "        context.create_expectation_suite(suite_name)\n",
    "    except Exception:\n",
    "        pass  # already exists\n",
    "\n",
    "    datasource_name = \"dq_datasource\"\n",
    "    if datasource_name not in context.datasources:\n",
    "        context.add_datasource(\n",
    "            name=datasource_name,\n",
    "            class_name=\"Datasource\",\n",
    "            execution_engine={\"class_name\": \"PandasExecutionEngine\"},\n",
    "            data_connectors={\n",
    "                \"runtime_data_connector\": {\n",
    "                    \"class_name\": \"RuntimeDataConnector\",\n",
    "                    \"batch_identifiers\": [\"default_id\"]\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "    batch_request = {\n",
    "        \"datasource_name\": datasource_name,\n",
    "        \"data_connector_name\": \"runtime_data_connector\",\n",
    "        \"data_asset_name\": \"dq_data_asset\",\n",
    "        \"runtime_parameters\": {\"batch_data\": df},\n",
    "        \"batch_identifiers\": {\"default_id\": \"dq_batch_01\"}\n",
    "    }\n",
    "\n",
    "    validator = context.get_validator(\n",
    "        batch_request=batch_request,\n",
    "        expectation_suite_name=suite_name\n",
    "    )\n",
    "\n",
    "    # Basic expectations\n",
    "    validator.expect_column_values_to_not_be_null(\"Name\")\n",
    "    validator.expect_column_values_to_not_be_null(\"Email\")\n",
    "    validator.expect_column_values_to_match_regex(\"Email\", \".+@.+\\\\..+\")\n",
    "    validator.expect_column_values_to_not_be_null(\"Age\")\n",
    "    validator.expect_column_values_to_be_between(\"Age\", 0, 120)\n",
    "    validator.expect_column_values_to_be_unique(\"Email\")\n",
    "\n",
    "    validator.save_expectation_suite()\n",
    "    return batch_request, suite_name\n",
    "\n",
    "# Step 4: Validate & Calculate Score\n",
    "def calculate_data_quality_score(context, batch_request, suite_name):\n",
    "    checkpoint = context.add_or_update_checkpoint(\n",
    "        name=\"dq_score_checkpoint\",\n",
    "        validations=[{\n",
    "            \"batch_request\": batch_request,\n",
    "            \"expectation_suite_name\": suite_name\n",
    "        }]\n",
    "    )\n",
    "\n",
    "    results = checkpoint.run()\n",
    "    validation_result = results.list_validation_results()[0]\n",
    "\n",
    "    total_expectations = len(validation_result[\"results\"])\n",
    "    passed = sum(1 for r in validation_result[\"results\"] if r[\"success\"])\n",
    "\n",
    "    dq_score = (passed / total_expectations) * 100\n",
    "    print(f\"\\nüìä Data Quality Score: {dq_score:.2f}% ({passed}/{total_expectations} expectations passed)\")\n",
    "\n",
    "    # Optionally: open the HTML report\n",
    "    context.build_data_docs()\n",
    "    print(\"üìÑ HTML Report:\", context.get_docs_sites_urls()[0][\"site_url\"])\n",
    "\n",
    "# === MAIN ===\n",
    "if __name__ == \"__main__\":\n",
    "    df = create_sample_csv()\n",
    "    context = get_ge_context()\n",
    "    batch_request, suite_name = create_expectations(context, df)\n",
    "    calculate_data_quality_score(context, batch_request, suite_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Leveraging Data Quality Metrics for Automated Data Cleaning\n",
    "**Description**: Implement a system where if data quality metrics fall below a threshold,\n",
    "automated data cleaning scripts are triggered.\n",
    "\n",
    "**Steps**:\n",
    "1. Define Cleaning Logic\n",
    "2. Integrate with Great Expectations:\n",
    "    - Use an action within the Great Expectations action list that only triggers if quality score is below a threshold, automating the cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EphemeralDataContext' object has no attribute 'datasources'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 138\u001b[0m\n\u001b[1;32m    136\u001b[0m df \u001b[38;5;241m=\u001b[39m create_sample_csv()\n\u001b[1;32m    137\u001b[0m context \u001b[38;5;241m=\u001b[39m gx\u001b[38;5;241m.\u001b[39mget_context()\n\u001b[0;32m--> 138\u001b[0m batch_request, suite_name \u001b[38;5;241m=\u001b[39m \u001b[43msetup_ge_and_expectations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m cleaned_df, final_score \u001b[38;5;241m=\u001b[39m run_validation_and_clean(context, batch_request, suite_name, df, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m85\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Optional: Save cleaned data\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 25\u001b[0m, in \u001b[0;36msetup_ge_and_expectations\u001b[0;34m(context, df)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Suite exists\u001b[39;00m\n\u001b[1;32m     24\u001b[0m ds_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdq_datasource\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ds_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasources\u001b[49m:\n\u001b[1;32m     26\u001b[0m     context\u001b[38;5;241m.\u001b[39madd_datasource(\n\u001b[1;32m     27\u001b[0m         name\u001b[38;5;241m=\u001b[39mds_name,\n\u001b[1;32m     28\u001b[0m         class_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasource\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m         }\n\u001b[1;32m     36\u001b[0m     )\n\u001b[1;32m     38\u001b[0m batch_request \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasource_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: ds_name,\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_connector_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruntime_data_connector\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_identifiers\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_001\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     44\u001b[0m }\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EphemeralDataContext' object has no attribute 'datasources'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import great_expectations as gx\n",
    "import re\n",
    "\n",
    "# Step 1: Create sample data with issues\n",
    "def create_sample_csv():\n",
    "    data = {\n",
    "        \"Name\": [\"Alice\", None, \"Charlie\", \"David\", \"Eve\"],\n",
    "        \"Email\": [\"alice@example.com\", \"bob@example.com\", \"invalid_email\", None, \"eve@example.com\"],\n",
    "        \"Age\": [25, 30, None, 22, 45]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(\"data_quality_sample.csv\", index=False)\n",
    "    return df\n",
    "\n",
    "# Step 2: Setup GE context and expectations\n",
    "def setup_ge_and_expectations(context, df):\n",
    "    suite_name = \"dq_cleaning_suite\"\n",
    "    try:\n",
    "        context.create_expectation_suite(suite_name)\n",
    "    except Exception:\n",
    "        pass  # Suite exists\n",
    "\n",
    "    ds_name = \"dq_datasource\"\n",
    "    if ds_name not in context.datasources:\n",
    "        context.add_datasource(\n",
    "            name=ds_name,\n",
    "            class_name=\"Datasource\",\n",
    "            execution_engine={\"class_name\": \"PandasExecutionEngine\"},\n",
    "            data_connectors={\n",
    "                \"runtime_data_connector\": {\n",
    "                    \"class_name\": \"RuntimeDataConnector\",\n",
    "                    \"batch_identifiers\": [\"default_id\"]\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "    batch_request = {\n",
    "        \"datasource_name\": ds_name,\n",
    "        \"data_connector_name\": \"runtime_data_connector\",\n",
    "        \"data_asset_name\": \"dq_data_asset\",\n",
    "        \"runtime_parameters\": {\"batch_data\": df},\n",
    "        \"batch_identifiers\": {\"default_id\": \"batch_001\"}\n",
    "    }\n",
    "\n",
    "    validator = context.get_validator(\n",
    "        batch_request=batch_request,\n",
    "        expectation_suite_name=suite_name\n",
    "    )\n",
    "\n",
    "    # Expectations\n",
    "    validator.expect_column_values_to_not_be_null(\"Name\")\n",
    "    validator.expect_column_values_to_not_be_null(\"Email\")\n",
    "    validator.expect_column_values_to_match_regex(\"Email\", r\".+@.+\\..+\")\n",
    "    validator.expect_column_values_to_not_be_null(\"Age\")\n",
    "    validator.expect_column_values_to_be_between(\"Age\", 0, 120)\n",
    "    validator.expect_column_values_to_be_unique(\"Email\")\n",
    "\n",
    "    validator.save_expectation_suite()\n",
    "\n",
    "    return batch_request, suite_name\n",
    "\n",
    "# Step 3: Calculate DQ score from validation results\n",
    "def calculate_dq_score(validation_results):\n",
    "    results = validation_results[\"results\"]\n",
    "    total = len(results)\n",
    "    passed = sum(1 for r in results if r[\"success\"])\n",
    "    score = (passed / total) * 100 if total > 0 else 0\n",
    "    return score\n",
    "\n",
    "# Step 4: Automated cleaning logic\n",
    "def clean_data(df):\n",
    "    print(\"‚öôÔ∏è Cleaning data...\")\n",
    "\n",
    "    # Drop rows where Name or Email or Age is null\n",
    "    df_cleaned = df.dropna(subset=[\"Name\", \"Email\", \"Age\"])\n",
    "\n",
    "    # Fix emails: remove invalid emails by filtering regex\n",
    "    df_cleaned = df_cleaned[df_cleaned[\"Email\"].str.match(r\".+@.+\\..+\")]\n",
    "\n",
    "    # Remove duplicates based on Email\n",
    "    df_cleaned = df_cleaned.drop_duplicates(subset=[\"Email\"])\n",
    "\n",
    "    print(f\"‚úÖ Cleaned data: {len(df)} -> {len(df_cleaned)} rows\")\n",
    "    return df_cleaned\n",
    "\n",
    "# Step 5: Run validation and optionally clean & re-validate\n",
    "def run_validation_and_clean(context, batch_request, suite_name, df, threshold=85):\n",
    "    checkpoint = context.add_or_update_checkpoint(\n",
    "        name=\"dq_checkpoint\",\n",
    "        validations=[{\n",
    "            \"batch_request\": batch_request,\n",
    "            \"expectation_suite_name\": suite_name\n",
    "        }]\n",
    "    )\n",
    "    result = checkpoint.run()\n",
    "    validation_result = result.list_validation_results()[0]\n",
    "    score = calculate_dq_score(validation_result)\n",
    "\n",
    "    print(f\"\\nüìä Data Quality Score: {score:.2f}%\")\n",
    "\n",
    "    if score < threshold:\n",
    "        print(f\"‚ö†Ô∏è Score below {threshold}%. Triggering cleaning...\")\n",
    "        df_cleaned = clean_data(df)\n",
    "\n",
    "        # Recreate batch_request with cleaned data\n",
    "        batch_request_cleaned = {\n",
    "            \"datasource_name\": batch_request[\"datasource_name\"],\n",
    "            \"data_connector_name\": batch_request[\"data_connector_name\"],\n",
    "            \"data_asset_name\": batch_request[\"data_asset_name\"],\n",
    "            \"runtime_parameters\": {\"batch_data\": df_cleaned},\n",
    "            \"batch_identifiers\": batch_request[\"batch_identifiers\"],\n",
    "        }\n",
    "\n",
    "        # Re-run validation on cleaned data\n",
    "        checkpoint_validated = context.add_or_update_checkpoint(\n",
    "            name=\"dq_checkpoint_cleaned\",\n",
    "            validations=[{\n",
    "                \"batch_request\": batch_request_cleaned,\n",
    "                \"expectation_suite_name\": suite_name\n",
    "            }]\n",
    "        )\n",
    "        cleaned_result = checkpoint_validated.run()\n",
    "        cleaned_validation_result = cleaned_result.list_validation_results()[0]\n",
    "        cleaned_score = calculate_dq_score(cleaned_validation_result)\n",
    "\n",
    "        print(f\"\\n‚úÖ Post-cleaning Data Quality Score: {cleaned_score:.2f}%\")\n",
    "        return df_cleaned, cleaned_score\n",
    "\n",
    "    else:\n",
    "        print(\"üëç Data quality is sufficient. No cleaning needed.\")\n",
    "        return df, score\n",
    "\n",
    "# === MAIN ===\n",
    "if __name__ == \"__main__\":\n",
    "    df = create_sample_csv()\n",
    "    context = gx.get_context()\n",
    "    batch_request, suite_name = setup_ge_and_expectations(context, df)\n",
    "\n",
    "    cleaned_df, final_score = run_validation_and_clean(context, batch_request, suite_name, df, threshold=85)\n",
    "\n",
    "    # Optional: Save cleaned data\n",
    "    cleaned_df.to_csv(\"cleaned_data.csv\", index=False)\n",
    "    print(\"\\n‚úÖ Cleaned data saved to cleaned_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
