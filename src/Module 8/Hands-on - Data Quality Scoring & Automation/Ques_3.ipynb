{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automate Data Quality Checks with Great Expectations\n",
    "**Introduction**: In this activity, you will learn how to automate data quality checks using the Great Expectations framework. This includes setting up expectations and generating validation reports.\n",
    "\n",
    "### Task 1: Setup and Initial Expectations\n",
    "\n",
    "1. Objective: Set up Great Expectations and create initial expectations for a dataset.\n",
    "2. Steps:\n",
    "    - Install Great Expectations using pip.\n",
    "    - Initialize a data context.\n",
    "    - Create basic expectations on a sample dataset.\n",
    "    - Eg., Implement a basic setup and expectation for column presence and type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data saved to sample_data.csv\n"
     ]
    },
    {
     "ename": "DataContextError",
     "evalue": "Datasource is not a FluentDatasource",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataContextError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 102\u001b[0m\n\u001b[1;32m     99\u001b[0m     validate_and_generate_report(context, validator, suite_name)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 102\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 97\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m create_sample_data(data_path)\n\u001b[0;32m---> 97\u001b[0m context, validator, suite_name \u001b[38;5;241m=\u001b[39m \u001b[43msetup_ge_context_and_suite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m validate_and_generate_report(context, validator, suite_name)\n",
      "Cell \u001b[0;32mIn[2], line 26\u001b[0m, in \u001b[0;36msetup_ge_context_and_suite\u001b[0;34m(data_path)\u001b[0m\n\u001b[1;32m     24\u001b[0m datasources \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mlist_datasources()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_pandas_datasource\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m datasources):\n\u001b[0;32m---> 26\u001b[0m     \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_datasource\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmy_pandas_datasource\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDatasource\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_engine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPandasExecutionEngine\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_connectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefault_runtime_data_connector_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRuntimeDataConnector\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_identifiers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefault_identifier_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m suite_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madvanced_expectations_suite\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/great_expectations/data_context/data_context/abstract_data_context.py:718\u001b[0m, in \u001b[0;36mAbstractDataContext.add_datasource\u001b[0;34m(self, name, initialize, datasource, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;129m@new_argument\u001b[39m(\n\u001b[1;32m    692\u001b[0m     argument_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasource\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    693\u001b[0m     version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.15.49\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    702\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FluentDatasource \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Add a new Datasource to the data context, with configuration provided as kwargs.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \n\u001b[1;32m    705\u001b[0m \u001b[38;5;124;03m    --Documentation--\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;124;03m        Datasource instance added.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 718\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_datasource\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitialize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatasource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatasource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/great_expectations/data_context/data_context/abstract_data_context.py:758\u001b[0m, in \u001b[0;36mAbstractDataContext._add_datasource\u001b[0;34m(self, name, initialize, datasource, **kwargs)\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_fluent_datasource(\n\u001b[1;32m    755\u001b[0m         datasource\u001b[38;5;241m=\u001b[39mdatasource,\n\u001b[1;32m    756\u001b[0m     )\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 758\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DataContextError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasource is not a FluentDatasource\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# noqa: TRY003 # FIXME CoP\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m datasource\n",
      "\u001b[0;31mDataContextError\u001b[0m: Datasource is not a FluentDatasource"
     ]
    }
   ],
   "source": [
    "import great_expectations as ge\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def create_sample_data(file_path):\n",
    "    data = {\n",
    "        \"CustomerID\": [1, 2, 3, 4, 4],  # Note: duplicate CustomerID 4 for uniqueness test\n",
    "        \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"David\"],\n",
    "        \"Email\": [\"alice@example.com\", \"bob@example.com\", \"charlie@example.com\", \"david@example.com\", None],\n",
    "        \"Age\": [25, 30, 35, 40, None]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Sample data saved to {file_path}\")\n",
    "\n",
    "def setup_ge_context_and_suite(data_path):\n",
    "    # Initialize GE context\n",
    "    context = ge.get_context()\n",
    "\n",
    "    # Load CSV using pandas\n",
    "    df = pd.read_csv(data_path)\n",
    "\n",
    "    # Add datasource if not exists\n",
    "    datasources = context.list_datasources()\n",
    "    if not any(ds[\"name\"] == \"my_pandas_datasource\" for ds in datasources):\n",
    "        context.add_datasource(\n",
    "            name=\"my_pandas_datasource\",\n",
    "            class_name=\"Datasource\",\n",
    "            execution_engine={\"class_name\": \"PandasExecutionEngine\"},\n",
    "            data_connectors={\n",
    "                \"default_runtime_data_connector_name\": {\n",
    "                    \"class_name\": \"RuntimeDataConnector\",\n",
    "                    \"batch_identifiers\": [\"default_identifier_name\"],\n",
    "                }\n",
    "            },\n",
    "        )\n",
    "\n",
    "    suite_name = \"advanced_expectations_suite\"\n",
    "    try:\n",
    "        context.delete_expectation_suite(suite_name)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    batch_request = {\n",
    "        \"datasource_name\": \"my_pandas_datasource\",\n",
    "        \"data_connector_name\": \"default_runtime_data_connector_name\",\n",
    "        \"data_asset_name\": \"runtime_data_asset\",\n",
    "        \"runtime_parameters\": {\"batch_data\": df},\n",
    "        \"batch_identifiers\": {\"default_identifier_name\": \"default\"},\n",
    "    }\n",
    "\n",
    "    # Create expectation suite\n",
    "    validator = context.get_validator(\n",
    "        batch_request=batch_request,\n",
    "        expectation_suite_name=suite_name,\n",
    "        create_expectation_suite=True,\n",
    "    )\n",
    "\n",
    "    # Define expectations\n",
    "\n",
    "    # Basic Completeness Expectations\n",
    "    validator.expect_column_to_exist(\"CustomerID\")\n",
    "    validator.expect_column_values_to_not_be_null(\"CustomerID\")\n",
    "    validator.expect_column_to_exist(\"Name\")\n",
    "    validator.expect_column_values_to_not_be_null(\"Name\")\n",
    "\n",
    "    # Email format validity and completeness\n",
    "    validator.expect_column_to_exist(\"Email\")\n",
    "    validator.expect_column_values_to_not_be_null(\"Email\")\n",
    "    validator.expect_column_values_to_match_regex(\"Email\", r\"[^@]+@[^@]+\\.[^@]+\")\n",
    "\n",
    "    # Age range check\n",
    "    validator.expect_column_to_exist(\"Age\")\n",
    "    validator.expect_column_values_to_be_between(\"Age\", min_value=0, max_value=120, mostly=0.8)\n",
    "\n",
    "    # Advanced expectation: CustomerID should be unique\n",
    "    validator.expect_column_values_to_be_unique(\"CustomerID\")\n",
    "\n",
    "    validator.save_expectation_suite(discard_failed_expectations=False)\n",
    "\n",
    "    print(f\"Expectation suite '{suite_name}' created and saved.\")\n",
    "    return context, validator, suite_name\n",
    "\n",
    "def validate_and_generate_report(context, validator, suite_name):\n",
    "    results = validator.validate()\n",
    "    print(\"\\nValidation Results Summary:\")\n",
    "    print(results)\n",
    "\n",
    "    # Build data docs and open report\n",
    "    context.build_data_docs()\n",
    "    context.open_data_docs()\n",
    "\n",
    "def main():\n",
    "    data_path = \"sample_data.csv\"\n",
    "    create_sample_data(data_path)\n",
    "\n",
    "    context, validator, suite_name = setup_ge_context_and_suite(data_path)\n",
    "\n",
    "    validate_and_generate_report(context, validator, suite_name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Validate Datasets and Generate Reports\n",
    "\n",
    "1. Objective: Validate a dataset against defined expectations and generate a report.\n",
    "2. Steps:\n",
    "    - Execute the validation process on the dataset.\n",
    "    - Review the validation results and generate a report.\n",
    "    - Eg., Validate completeness and consistency expectations, and view the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file '/workspaces/AI_DATA_ANALYSIS_/src/Module 8/Hands-on - Data Quality Scoring & Automation/validate_and_report.py': [Errno 2] No such file or directory\n",
      "Sample data saved to sample_data.csv\n"
     ]
    },
    {
     "ename": "DataContextError",
     "evalue": "Datasource is not a FluentDatasource",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataContextError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 91\u001b[0m\n\u001b[1;32m     88\u001b[0m     validate_and_generate_report(context, validator, suite_name)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 91\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 86\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m create_sample_data(data_path)\n\u001b[0;32m---> 86\u001b[0m context, validator, suite_name \u001b[38;5;241m=\u001b[39m \u001b[43msetup_ge_context_and_suite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m validate_and_generate_report(context, validator, suite_name)\n",
      "Cell \u001b[0;32mIn[6], line 27\u001b[0m, in \u001b[0;36msetup_ge_context_and_suite\u001b[0;34m(data_path)\u001b[0m\n\u001b[1;32m     25\u001b[0m datasources \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mlist_datasources()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas_datasource\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m datasources):\n\u001b[0;32m---> 27\u001b[0m     \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_datasource\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpandas_datasource\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDatasource\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_engine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPandasExecutionEngine\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_connectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefault_runtime_data_connector_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRuntimeDataConnector\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_identifiers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefault_identifier_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m suite_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleteness_consistency_suite\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Delete if exists\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/great_expectations/data_context/data_context/abstract_data_context.py:718\u001b[0m, in \u001b[0;36mAbstractDataContext.add_datasource\u001b[0;34m(self, name, initialize, datasource, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;129m@new_argument\u001b[39m(\n\u001b[1;32m    692\u001b[0m     argument_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasource\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    693\u001b[0m     version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.15.49\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    702\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FluentDatasource \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Add a new Datasource to the data context, with configuration provided as kwargs.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \n\u001b[1;32m    705\u001b[0m \u001b[38;5;124;03m    --Documentation--\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;124;03m        Datasource instance added.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 718\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_datasource\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitialize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatasource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatasource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/great_expectations/data_context/data_context/abstract_data_context.py:758\u001b[0m, in \u001b[0;36mAbstractDataContext._add_datasource\u001b[0;34m(self, name, initialize, datasource, **kwargs)\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_fluent_datasource(\n\u001b[1;32m    755\u001b[0m         datasource\u001b[38;5;241m=\u001b[39mdatasource,\n\u001b[1;32m    756\u001b[0m     )\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 758\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DataContextError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasource is not a FluentDatasource\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# noqa: TRY003 # FIXME CoP\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m datasource\n",
      "\u001b[0;31mDataContextError\u001b[0m: Datasource is not a FluentDatasource"
     ]
    }
   ],
   "source": [
    "!python validate_and_report.py\n",
    "import great_expectations as ge\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def create_sample_data(file_path):\n",
    "    data = {\n",
    "        \"ID\": [1, 2, 3, 4, 5],\n",
    "        \"Name\": [\"Alice\", \"Bob\", \"Charlie\", None, \"Eve\"],\n",
    "        \"Email\": [\"alice@example.com\", \"bob@example\", \"charlie@example.com\", \"david@example.com\", None],\n",
    "        \"Age\": [25, 30, 35, 40, 28]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Sample data saved to {file_path}\")\n",
    "\n",
    "def setup_ge_context_and_suite(data_path):\n",
    "    # Initialize GE context\n",
    "    context = ge.get_context()\n",
    "\n",
    "    # Load data with pandas\n",
    "    df = pd.read_csv(data_path)\n",
    "\n",
    "    # Add pandas datasource if not exists\n",
    "    datasources = context.list_datasources()\n",
    "    if not any(ds[\"name\"] == \"pandas_datasource\" for ds in datasources):\n",
    "        context.add_datasource(\n",
    "            name=\"pandas_datasource\",\n",
    "            class_name=\"Datasource\",\n",
    "            execution_engine={\"class_name\": \"PandasExecutionEngine\"},\n",
    "            data_connectors={\n",
    "                \"default_runtime_data_connector_name\": {\n",
    "                    \"class_name\": \"RuntimeDataConnector\",\n",
    "                    \"batch_identifiers\": [\"default_identifier_name\"],\n",
    "                }\n",
    "            },\n",
    "        )\n",
    "\n",
    "    suite_name = \"completeness_consistency_suite\"\n",
    "    # Delete if exists\n",
    "    try:\n",
    "        context.delete_expectation_suite(suite_name)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    batch_request = {\n",
    "        \"datasource_name\": \"pandas_datasource\",\n",
    "        \"data_connector_name\": \"default_runtime_data_connector_name\",\n",
    "        \"data_asset_name\": \"runtime_data_asset\",\n",
    "        \"runtime_parameters\": {\"batch_data\": df},\n",
    "        \"batch_identifiers\": {\"default_identifier_name\": \"default\"},\n",
    "    }\n",
    "\n",
    "    validator = context.get_validator(\n",
    "        batch_request=batch_request,\n",
    "        expectation_suite_name=suite_name,\n",
    "        create_expectation_suite=True,\n",
    "    )\n",
    "\n",
    "    # Define Completeness Expectations (non-null)\n",
    "    validator.expect_column_values_to_not_be_null(\"Name\")\n",
    "    validator.expect_column_values_to_not_be_null(\"Email\")\n",
    "\n",
    "    # Define Consistency Expectation - Email format (basic regex)\n",
    "    validator.expect_column_values_to_match_regex(\"Email\", r\"[^@]+@[^@]+\\.[^@]+\")\n",
    "\n",
    "    validator.save_expectation_suite()\n",
    "    print(f\"Expectation suite '{suite_name}' created.\")\n",
    "\n",
    "    return context, validator, suite_name\n",
    "\n",
    "def validate_and_generate_report(context, validator, suite_name):\n",
    "    # Validate the data\n",
    "    results = validator.validate()\n",
    "    print(\"\\nValidation Results Summary:\")\n",
    "    print(results)\n",
    "\n",
    "    # Build and open data docs (HTML report)\n",
    "    context.build_data_docs()\n",
    "    context.open_data_docs()\n",
    "\n",
    "def main():\n",
    "    data_path = \"sample_data.csv\"\n",
    "    create_sample_data(data_path)\n",
    "\n",
    "    context, validator, suite_name = setup_ge_context_and_suite(data_path)\n",
    "\n",
    "    validate_and_generate_report(context, validator, suite_name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Advanced Expectations and Scheduling\n",
    "\n",
    "1. Objective: Create advanced expectations for conditional checks and automate the validation.\n",
    "2. Steps:\n",
    "    - Define advanced expectations based on complex conditions.\n",
    "    - Use scheduling tools to automate periodic checks.\n",
    "    - E.g., an expectation that customer IDs must be unique and schedule a daily check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data saved to sample_data.csv\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'great_expectations' has no attribute 'from_pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m     run_validation(validator)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 60\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 55\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     54\u001b[0m df \u001b[38;5;241m=\u001b[39m create_sample_data(data_path)\n\u001b[0;32m---> 55\u001b[0m validator \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_validator_from_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m validator \u001b[38;5;241m=\u001b[39m add_expectations(validator)\n\u001b[1;32m     57\u001b[0m run_validation(validator)\n",
      "Cell \u001b[0;32mIn[9], line 18\u001b[0m, in \u001b[0;36mcreate_validator_from_df\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_validator_from_df\u001b[39m(df):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Create Great Expectations validator directly from pandas DataFrame\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     validator \u001b[38;5;241m=\u001b[39m \u001b[43mge\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m(df)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m validator\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'great_expectations' has no attribute 'from_pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import great_expectations as ge\n",
    "\n",
    "def create_sample_data(file_path):\n",
    "    data = {\n",
    "        \"CustomerID\": [101, 102, 103, 104, 102],  # Duplicate CustomerID to test uniqueness\n",
    "        \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"],\n",
    "        \"Email\": [\"alice@example.com\", \"bob@example.com\", None, \"david@example.com\", \"eve@example.com\"],\n",
    "        \"Age\": [25, 30, 17, 40, 22]  # 17 is underage with Email, to trigger manual check\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Sample data saved to {file_path}\")\n",
    "    return df\n",
    "\n",
    "def create_validator_from_df(df):\n",
    "    # Create Great Expectations validator directly from pandas DataFrame\n",
    "    validator = ge.from_pandas(df)\n",
    "    return validator\n",
    "\n",
    "def add_expectations(validator):\n",
    "    # Expect CustomerID to be unique\n",
    "    validator.expect_column_values_to_be_unique(\"CustomerID\")\n",
    "\n",
    "    # Expect no nulls in CustomerID and Name\n",
    "    validator.expect_column_values_to_not_be_null(\"CustomerID\")\n",
    "    validator.expect_column_values_to_not_be_null(\"Name\")\n",
    "\n",
    "    # Expect Email column to contain '@' (validity check)\n",
    "    validator.expect_column_values_to_match_regex(\"Email\", r\".+@.+\\..+\")\n",
    "\n",
    "    # Manually check conditional expectation: If Email is not null, Age must be > 18\n",
    "    invalid_rows = validator.df[(validator.df[\"Email\"].notna()) & (validator.df[\"Age\"] <= 18)]\n",
    "    if not invalid_rows.empty:\n",
    "        print(\"\\nWarning: Rows where Email is present but Age <= 18 (failed conditional check):\")\n",
    "        print(invalid_rows)\n",
    "    else:\n",
    "        print(\"\\nConditional check passed: All Email holders are older than 18.\")\n",
    "\n",
    "    return validator\n",
    "\n",
    "def run_validation(validator):\n",
    "    # Run validation and get results\n",
    "    results = validator.validate()\n",
    "    print(\"\\nValidation Results Summary:\")\n",
    "    print(f\"Success: {results['success']}\")\n",
    "    for res in results['results']:\n",
    "        exp_type = res['expectation_config']['expectation_type']\n",
    "        success = res['success']\n",
    "        print(f\" - Expectation {exp_type} passed: {success}\")\n",
    "\n",
    "def main():\n",
    "    data_path = \"sample_data.csv\"\n",
    "    df = create_sample_data(data_path)\n",
    "    validator = create_validator_from_df(df)\n",
    "    validator = add_expectations(validator)\n",
    "    run_validation(validator)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
